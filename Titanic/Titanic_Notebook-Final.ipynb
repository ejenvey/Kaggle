{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of my main findings thus far:\n",
    "* Started without feature engineering, only performed data cleaning, ended with XGBoost algorithm with Grid Search which gave me roughly 88% training accuracy\n",
    "* Then followed Sima's excellent feature engineering post, just to get some experience with different techniques for handling different data types, used the same model with Grid Search, and ended with an 83% training accuracy...ended up here that without GridSearch, using the default XGBoost, I was able to get better test set performance (via the submission)\n",
    "* Next step will be to ensemble the models, using another Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import KFold\n",
    "from xgboost import XGBClassifier\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv(\"train.csv\")\n",
    "testing = pd.read_csv(\"test.csv\")\n",
    "\n",
    "full_data = [training,testing]\n",
    "\n",
    "PassengerId = testing['PassengerId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dataset in full_data:\n",
    "    \n",
    "    dataset[\"Pclass\"] = dataset[\"Pclass\"].astype(\"category\")\n",
    "    dataset[\"Sex\"] = dataset[\"Sex\"].astype(\"category\")\n",
    "    dataset[\"Embarked\"] = dataset[\"Embarked\"].astype(\"category\")\n",
    "\n",
    "training[\"Survived\"] = training[\"Survived\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Most of this section is credited to Sina, for her excellent feature engineering Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ejenvey/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:24: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Empty Embarked values, fill with the most common\n",
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "\n",
    "#Creating a Family Size feature that combines number of siblings/spouse and number of children/parents\n",
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    \n",
    "#IsAlone - based off Family Size to separate those with no family from those with family\n",
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    \n",
    "#Categorize Fare into buckets\n",
    "training['CategoricalFare'] = pd.qcut(training['Fare'],4)\n",
    "\n",
    "#To Deal with Age, we can impute values for the 177 missing Ages, then categorize them like the Fare\n",
    "#Using mean +/- 2*standard deviation as the range of values that the missing values can take\n",
    "for dataset in full_data:\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(age_avg-(2*age_std), age_avg+(2*age_std),size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    \n",
    "#Then split these ages for the Training set\n",
    "training['CategoricalAge'] = pd.cut(training['Age'],5)\n",
    "\n",
    "#Apply the binning for Age and Fare from the training set to the test set\n",
    "testing.loc[ testing['Fare'] <= 7.91,'CategoricalFare'] = \"(-0.001,7.91]\"\n",
    "testing.loc[(testing['Fare'] > 7.91) & (testing['Fare'] <= 14.454), 'CategoricalFare'] = \"(7.91,14.454]\"\n",
    "testing.loc[(testing['Fare'] > 14.454) & (testing['Fare'] <= 31.0), 'CategoricalFare'] = \"(14.454, 31.0]\"\n",
    "testing.loc[testing['Fare'] > 31.0, 'CategoricalFare'] = \"(31.0, 512.329]\"\n",
    "\n",
    "testing.loc[ testing['Age'] <= 16.0,'CategoricalAge'] = \"(-0.08, 16.0]\"\n",
    "testing.loc[(testing['Age'] > 16.0) & (testing['Age'] <= 32.0), 'CategoricalAge'] = \"(16.0, 32.0]\"\n",
    "testing.loc[(testing['Age'] > 32.0) & (testing['Age'] <= 48.0), 'CategoricalAge'] = \"(32.0, 48.0]\"\n",
    "testing.loc[(testing['Age'] > 48.0) & (testing['Age'] <= 64.0), 'CategoricalAge'] = \"(48.0, 64.0]\"\n",
    "testing.loc[ testing['Age'] > 64.0,'CategoricalAge'] = \"(64.0, 80.0]\"\n",
    "\n",
    "#Final data conversions\n",
    "for dataset in full_data:\n",
    "    dataset[\"FamilySize\"] = dataset[\"FamilySize\"].astype(\"category\")\n",
    "    dataset['IsAlone'] = dataset['IsAlone'].astype('category')\n",
    "    dataset['CategoricalFare'] = dataset['CategoricalFare'].astype('category')\n",
    "    dataset['CategoricalAge'] = dataset['CategoricalAge'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding\n",
    "Taking all categorical variables and performing one-hot encoding.  Then, removing one of the categories (can be done via the parameter within get_dummies, but doing it here explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in training.select_dtypes(include=['category']).columns:\n",
    "    dummy_columns = pd.get_dummies(data=training[column],prefix=column)\n",
    "    training = pd.merge(training, pd.DataFrame(dummy_columns.iloc[:,1:]), left_index=True, right_index=True)\n",
    "\n",
    "for column in testing.select_dtypes(include=['category']).columns:\n",
    "    dummy_columns = pd.get_dummies(data=testing[column],prefix=column)\n",
    "    testing = pd.merge(testing, pd.DataFrame(dummy_columns.iloc[:,1:]), left_index=True, right_index=True)\n",
    "    \n",
    "for column in training.select_dtypes(include=['uint8']).columns:\n",
    "    training[column] = training[column].astype(np.int32)\n",
    "\n",
    "for column in testing.select_dtypes(include=['uint8']).columns:\n",
    "    testing[column] = testing[column].astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep for Modeling - Encoded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training= training.drop(['Age','SibSp','Parch','Pclass','Sex','Embarked','FamilySize','IsAlone','CategoricalFare','CategoricalAge','Name','Ticket','Fare','Cabin'],axis=1)\n",
    "testing= testing.drop(['Age','SibSp','Parch','Pclass','Sex','Embarked','FamilySize','IsAlone','CategoricalFare','CategoricalAge','Name','Ticket','Fare','Cabin'],axis=1)\n",
    "\n",
    "y_train = training.iloc[:,1]\n",
    "X_train = training.drop([\"Survived\",\"PassengerId\"],axis=1)\n",
    "X_test = testing.drop([\"PassengerId\"], axis=1)\n",
    "\n",
    "#Remove [] from variable names:\n",
    "X_train.columns = [['Pclass_2', 'Pclass_3', 'Sex_male', 'Embarked_Q', 'Embarked_S',\n",
    "       'FamilySize_2', 'FamilySize_3', 'FamilySize_4', 'FamilySize_5',\n",
    "       'FamilySize_6', 'FamilySize_7', 'FamilySize_8', 'FamilySize_11',\n",
    "       'IsAlone_1', 'CategoricalFare_(7.91-14.454)',\n",
    "       'CategoricalFare_(14.454-31.0)', 'CategoricalFare_(31.0-512.329)',\n",
    "       'CategoricalAge_(16.0-32.0)', 'CategoricalAge_(32.0-48.0)',\n",
    "       'CategoricalAge_(48.0-64.0)', 'CategoricalAge_(64.0-80.0)']]\n",
    "X_test.columns = [['Pclass_2', 'Pclass_3', 'Sex_male', 'Embarked_Q', 'Embarked_S',\n",
    "       'FamilySize_2', 'FamilySize_3', 'FamilySize_4', 'FamilySize_5',\n",
    "       'FamilySize_6', 'FamilySize_7', 'FamilySize_8', 'FamilySize_11',\n",
    "       'IsAlone_1', 'CategoricalFare_(7.91-14.454)',\n",
    "       'CategoricalFare_(14.454-31.0)', 'CategoricalFare_(31.0-512.329)',\n",
    "       'CategoricalAge_(16.0-32.0)', 'CategoricalAge_(32.0-48.0)',\n",
    "       'CategoricalAge_(48.0-64.0)', 'CategoricalAge_(64.0-80.0)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep for Modeling - Non-Encoded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in full_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    \n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # Mapping Fare\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(0)\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare']         = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare']       = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age']      = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4 ;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "training = training.drop(['PassengerId', 'Name', 'Ticket', 'CategoricalFare', 'CategoricalAge', 'Cabin'], axis=1)\n",
    "testing = testing.drop(['PassengerId', 'Name', 'Ticket', 'CategoricalFare', 'CategoricalAge', 'Cabin'], axis=1) \n",
    "y_train = training.iloc[:,0]\n",
    "X_train = training.drop([\"Survived\"],axis=1)\n",
    "X_test = testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived Pclass  Sex  Age  SibSp  Parch  Fare  Embarked FamilySize IsAlone\n",
       "0         0      3    1    1      1      0     0         0          2       0\n",
       "1         1      1    0    2      1      0     3         1          2       0\n",
       "2         1      3    0    1      0      0     1         0          1       1\n",
       "3         1      1    0    2      1      0     3         0          2       0\n",
       "4         0      3    1    2      0      0     1         0          1       1"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = training.shape[0]\n",
    "ntest = testing.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I do not understand this part, need to gain understanding here in order to really understand the ensemble.  He says \"you cannot train the base models on the full training data, generate predictions of the test set, then output these for the second-level training\"\n",
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "        \n",
    "        #changed this to fit, I didn't override scikit-learn\n",
    "        clf.fit(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to ensemble, I will need to generate multiple models, will start with the same ones he uses, in addition to my XGBoost above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs = -1, \n",
    "                            n_estimators = 500,\n",
    "                            criterion = \"entropy\",\n",
    "                            warm_start = True,\n",
    "                            max_depth = 6,\n",
    "                            min_samples_leaf = 2,\n",
    "                            max_features = 'sqrt',\n",
    "                            verbose=0,\n",
    "                            random_state = 0)\n",
    "#rf.fit(X_train, y_train)\n",
    "\n",
    "et = ExtraTreesClassifier(n_jobs = -1,\n",
    "                         n_estimators = 500,\n",
    "                         max_depth = 8,\n",
    "                         min_samples_leaf = 2,\n",
    "                         verbose = 0)\n",
    "#et.fit(X_train,y_train)\n",
    "\n",
    "ada = AdaBoostClassifier(n_estimators = 500, learning_rate = 0.75)\n",
    "#ada.fit(X_train,y_train)\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators = 500,\n",
    "                               max_depth = 5,\n",
    "                               min_samples_leaf = 2,\n",
    "                               verbose = 0)\n",
    "#gb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "xg = XGBClassifier(learning_rate=1, \n",
    "                   gamma=0.2,\n",
    "                   max_depth=2, \n",
    "                   n_estimators=200,\n",
    "                   base_score=0.1,\n",
    "                   min_child_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\n",
    "x_train = X_train.values # Creates an array of the train data\n",
    "x_test = X_test.values # Creats an array of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\n",
    "rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\n",
    "ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \n",
    "gb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) # Gradient Boost\n",
    "xg_oof_train, xg_oof_test = get_oof(xg, x_train, y_train, x_test) #XG Boost\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feature = rf.feature_importances_\n",
    "et_feature = et.feature_importances_\n",
    "ada_feature = ada.feature_importances_\n",
    "gb_feature = gb.feature_importances_\n",
    "xg_feature = xg.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.columns.values\n",
    "# Create a dataframe with features\n",
    "feature_dataframe = pd.DataFrame( {'features': cols,\n",
    "     'Random Forest feature importances': rf_feature,\n",
    "     'Extra Trees  feature importances': et_feature,\n",
    "      'AdaBoost feature importances': ada_feature,\n",
    "    'Gradient Boost feature importances': gb_feature,\n",
    "    'XG Boost feature importances': xg_feature\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost feature importances</th>\n",
       "      <th>Extra Trees  feature importances</th>\n",
       "      <th>Gradient Boost feature importances</th>\n",
       "      <th>Random Forest feature importances</th>\n",
       "      <th>XG Boost feature importances</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044</td>\n",
       "      <td>0.173857</td>\n",
       "      <td>0.144640</td>\n",
       "      <td>0.186106</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>Pclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018</td>\n",
       "      <td>0.548245</td>\n",
       "      <td>0.091364</td>\n",
       "      <td>0.392919</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>Sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028</td>\n",
       "      <td>0.049631</td>\n",
       "      <td>0.171638</td>\n",
       "      <td>0.073164</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.258</td>\n",
       "      <td>0.027406</td>\n",
       "      <td>0.071209</td>\n",
       "      <td>0.042813</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>SibSp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.216</td>\n",
       "      <td>0.023102</td>\n",
       "      <td>0.047434</td>\n",
       "      <td>0.033303</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>Parch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.018</td>\n",
       "      <td>0.074748</td>\n",
       "      <td>0.182166</td>\n",
       "      <td>0.126488</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>Fare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.038717</td>\n",
       "      <td>0.139330</td>\n",
       "      <td>0.039577</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>Embarked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.388</td>\n",
       "      <td>0.042434</td>\n",
       "      <td>0.111802</td>\n",
       "      <td>0.080798</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>FamilySize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.021860</td>\n",
       "      <td>0.040416</td>\n",
       "      <td>0.024831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>IsAlone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AdaBoost feature importances  Extra Trees  feature importances  \\\n",
       "0                         0.044                          0.173857   \n",
       "1                         0.018                          0.548245   \n",
       "2                         0.028                          0.049631   \n",
       "3                         0.258                          0.027406   \n",
       "4                         0.216                          0.023102   \n",
       "5                         0.018                          0.074748   \n",
       "6                         0.016                          0.038717   \n",
       "7                         0.388                          0.042434   \n",
       "8                         0.014                          0.021860   \n",
       "\n",
       "   Gradient Boost feature importances  Random Forest feature importances  \\\n",
       "0                            0.144640                           0.186106   \n",
       "1                            0.091364                           0.392919   \n",
       "2                            0.171638                           0.073164   \n",
       "3                            0.071209                           0.042813   \n",
       "4                            0.047434                           0.033303   \n",
       "5                            0.182166                           0.126488   \n",
       "6                            0.139330                           0.039577   \n",
       "7                            0.111802                           0.080798   \n",
       "8                            0.040416                           0.024831   \n",
       "\n",
       "   XG Boost feature importances    features  \n",
       "0                      0.105263      Pclass  \n",
       "1                      0.087719         Sex  \n",
       "2                      0.245614         Age  \n",
       "3                      0.087719       SibSp  \n",
       "4                      0.070175       Parch  \n",
       "5                      0.070175        Fare  \n",
       "6                      0.087719    Embarked  \n",
       "7                      0.245614  FamilySize  \n",
       "8                      0.000000     IsAlone  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost feature importances</th>\n",
       "      <th>Extra Trees  feature importances</th>\n",
       "      <th>Gradient Boost feature importances</th>\n",
       "      <th>Random Forest feature importances</th>\n",
       "      <th>XG Boost feature importances</th>\n",
       "      <th>features</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044</td>\n",
       "      <td>0.173857</td>\n",
       "      <td>0.144640</td>\n",
       "      <td>0.186106</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.130773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018</td>\n",
       "      <td>0.548245</td>\n",
       "      <td>0.091364</td>\n",
       "      <td>0.392919</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>Sex</td>\n",
       "      <td>0.227650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028</td>\n",
       "      <td>0.049631</td>\n",
       "      <td>0.171638</td>\n",
       "      <td>0.073164</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>Age</td>\n",
       "      <td>0.113610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.258</td>\n",
       "      <td>0.027406</td>\n",
       "      <td>0.071209</td>\n",
       "      <td>0.042813</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.097429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.216</td>\n",
       "      <td>0.023102</td>\n",
       "      <td>0.047434</td>\n",
       "      <td>0.033303</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>Parch</td>\n",
       "      <td>0.078003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AdaBoost feature importances  Extra Trees  feature importances  \\\n",
       "0                         0.044                          0.173857   \n",
       "1                         0.018                          0.548245   \n",
       "2                         0.028                          0.049631   \n",
       "3                         0.258                          0.027406   \n",
       "4                         0.216                          0.023102   \n",
       "\n",
       "   Gradient Boost feature importances  Random Forest feature importances  \\\n",
       "0                            0.144640                           0.186106   \n",
       "1                            0.091364                           0.392919   \n",
       "2                            0.171638                           0.073164   \n",
       "3                            0.071209                           0.042813   \n",
       "4                            0.047434                           0.033303   \n",
       "\n",
       "   XG Boost feature importances features      mean  \n",
       "0                      0.105263   Pclass  0.130773  \n",
       "1                      0.087719      Sex  0.227650  \n",
       "2                      0.245614      Age  0.113610  \n",
       "3                      0.087719    SibSp  0.097429  \n",
       "4                      0.070175    Parch  0.078003  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the new column containing the average of values\n",
    "\n",
    "feature_dataframe['mean'] = feature_dataframe.mean(axis= 1)\n",
    "feature_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": [
           0.130773316628579,
           0.22764961858958274,
           0.11360953566322471,
           0.09742943701625148,
           0.07800278026360671,
           0.09431542669220919,
           0.06426878264845884,
           0.17372959460194498,
           0.02022150938625853
          ],
          "colorscale": "Portland",
          "reversescale": false,
          "showscale": true
         },
         "opacity": 0.6,
         "type": "bar",
         "width": 0.5,
         "x": [
          "Pclass",
          "Sex",
          "Age",
          "SibSp",
          "Parch",
          "Fare",
          "Embarked",
          "FamilySize",
          "IsAlone"
         ],
         "y": [
          0.130773316628579,
          0.22764961858958274,
          0.11360953566322471,
          0.09742943701625148,
          0.07800278026360671,
          0.09431542669220919,
          0.06426878264845884,
          0.17372959460194498,
          0.02022150938625853
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "hovermode": "closest",
        "showlegend": false,
        "title": "Barplots of Mean Feature Importance",
        "yaxis": {
         "gridwidth": 2,
         "ticklen": 5,
         "title": "Feature Importance"
        }
       }
      },
      "text/html": [
       "<div id=\"196b94cc-1b70-4583-a8f9-0fed16a85045\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"196b94cc-1b70-4583-a8f9-0fed16a85045\", [{\"opacity\": 0.6, \"width\": 0.5, \"y\": [0.130773316628579, 0.22764961858958274, 0.11360953566322471, 0.09742943701625148, 0.07800278026360671, 0.09431542669220919, 0.06426878264845884, 0.17372959460194498, 0.02022150938625853], \"x\": [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"IsAlone\"], \"type\": \"bar\", \"marker\": {\"reversescale\": false, \"color\": [0.130773316628579, 0.22764961858958274, 0.11360953566322471, 0.09742943701625148, 0.07800278026360671, 0.09431542669220919, 0.06426878264845884, 0.17372959460194498, 0.02022150938625853], \"showscale\": true, \"colorscale\": \"Portland\"}}], {\"autosize\": true, \"title\": \"Barplots of Mean Feature Importance\", \"showlegend\": false, \"hovermode\": \"closest\", \"yaxis\": {\"ticklen\": 5, \"gridwidth\": 2, \"title\": \"Feature Importance\"}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"196b94cc-1b70-4583-a8f9-0fed16a85045\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"196b94cc-1b70-4583-a8f9-0fed16a85045\", [{\"opacity\": 0.6, \"width\": 0.5, \"y\": [0.130773316628579, 0.22764961858958274, 0.11360953566322471, 0.09742943701625148, 0.07800278026360671, 0.09431542669220919, 0.06426878264845884, 0.17372959460194498, 0.02022150938625853], \"x\": [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"IsAlone\"], \"type\": \"bar\", \"marker\": {\"reversescale\": false, \"color\": [0.130773316628579, 0.22764961858958274, 0.11360953566322471, 0.09742943701625148, 0.07800278026360671, 0.09431542669220919, 0.06426878264845884, 0.17372959460194498, 0.02022150938625853], \"showscale\": true, \"colorscale\": \"Portland\"}}], {\"autosize\": true, \"title\": \"Barplots of Mean Feature Importance\", \"showlegend\": false, \"hovermode\": \"closest\", \"yaxis\": {\"ticklen\": 5, \"gridwidth\": 2, \"title\": \"Feature Importance\"}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = feature_dataframe['mean'].values\n",
    "x = feature_dataframe['features'].values\n",
    "data = [go.Bar(\n",
    "            x= x,\n",
    "             y= y,\n",
    "            width = 0.5,\n",
    "            marker=dict(\n",
    "               color = feature_dataframe['mean'].values,\n",
    "            colorscale='Portland',\n",
    "            showscale=True,\n",
    "            reversescale = False\n",
    "            ),\n",
    "            opacity=0.6\n",
    "        )]\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'Barplots of Mean Feature Importance',\n",
    "    hovermode= 'closest',\n",
    "#     xaxis= dict(\n",
    "#         title= 'Pop',\n",
    "#         ticklen= 5,\n",
    "#         zeroline= False,\n",
    "#         gridwidth= 2,\n",
    "#     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='bar-direct-labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>GradientBoost</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AdaBoost  ExtraTrees  GradientBoost  RandomForest  XGBoost\n",
       "0       0.0         0.0            0.0           0.0      0.0\n",
       "1       1.0         1.0            1.0           1.0      1.0\n",
       "2       1.0         0.0            0.0           0.0      0.0\n",
       "3       1.0         1.0            1.0           1.0      1.0\n",
       "4       0.0         0.0            0.0           0.0      0.0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictions_train = pd.DataFrame( {'RandomForest': rf_oof_train.ravel(),\n",
    "     'ExtraTrees': et_oof_train.ravel(),\n",
    "     'AdaBoost': ada_oof_train.ravel(),\n",
    "      'GradientBoost': gb_oof_train.ravel(),\n",
    "     'XGBoost': xg_oof_train.ravel()\n",
    "    })\n",
    "base_predictions_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "colorscale": "Portland",
         "reversescale": true,
         "showscale": true,
         "type": "heatmap",
         "x": [
          "AdaBoost",
          "ExtraTrees",
          "GradientBoost",
          "RandomForest",
          "XGBoost"
         ],
         "y": [
          "AdaBoost",
          "ExtraTrees",
          "GradientBoost",
          "RandomForest",
          "XGBoost"
         ],
         "z": [
          [
           1,
           0.7642376942635627,
           0.6467978756062853,
           0.7416118081075443,
           0.7456588542710453
          ],
          [
           0.7642376942635627,
           1,
           0.8296605820255605,
           0.8340650043994753,
           0.8223191474849488
          ],
          [
           0.6467978756062853,
           0.8296605820255605,
           1,
           0.7523097191207526,
           0.7325522410885887
          ],
          [
           0.7416118081075443,
           0.8340650043994753,
           0.7523097191207526,
           1,
           0.7762463158327337
          ],
          [
           0.7456588542710453,
           0.8223191474849488,
           0.7325522410885887,
           0.7762463158327337,
           1
          ]
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"3217f048-d934-4959-b7c5-2ba2a32d1344\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"3217f048-d934-4959-b7c5-2ba2a32d1344\", [{\"colorscale\": \"Portland\", \"reversescale\": true, \"showscale\": true, \"y\": [\"AdaBoost\", \"ExtraTrees\", \"GradientBoost\", \"RandomForest\", \"XGBoost\"], \"x\": [\"AdaBoost\", \"ExtraTrees\", \"GradientBoost\", \"RandomForest\", \"XGBoost\"], \"z\": [[1.0, 0.7642376942635627, 0.6467978756062853, 0.7416118081075443, 0.7456588542710453], [0.7642376942635627, 1.0, 0.8296605820255605, 0.8340650043994753, 0.8223191474849488], [0.6467978756062853, 0.8296605820255605, 1.0, 0.7523097191207526, 0.7325522410885887], [0.7416118081075443, 0.8340650043994753, 0.7523097191207526, 1.0, 0.7762463158327337], [0.7456588542710453, 0.8223191474849488, 0.7325522410885887, 0.7762463158327337, 1.0]], \"type\": \"heatmap\"}], {}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"3217f048-d934-4959-b7c5-2ba2a32d1344\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"3217f048-d934-4959-b7c5-2ba2a32d1344\", [{\"colorscale\": \"Portland\", \"reversescale\": true, \"showscale\": true, \"y\": [\"AdaBoost\", \"ExtraTrees\", \"GradientBoost\", \"RandomForest\", \"XGBoost\"], \"x\": [\"AdaBoost\", \"ExtraTrees\", \"GradientBoost\", \"RandomForest\", \"XGBoost\"], \"z\": [[1.0, 0.7642376942635627, 0.6467978756062853, 0.7416118081075443, 0.7456588542710453], [0.7642376942635627, 1.0, 0.8296605820255605, 0.8340650043994753, 0.8223191474849488], [0.6467978756062853, 0.8296605820255605, 1.0, 0.7523097191207526, 0.7325522410885887], [0.7416118081075443, 0.8340650043994753, 0.7523097191207526, 1.0, 0.7762463158327337], [0.7456588542710453, 0.8223191474849488, 0.7325522410885887, 0.7762463158327337, 1.0]], \"type\": \"heatmap\"}], {}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Show a heatmap of the correlation between predictions, ideally, we'd have little-to-no correlation\n",
    "data = [\n",
    "    go.Heatmap(\n",
    "        z= base_predictions_train.astype(float).corr().values ,\n",
    "        x=base_predictions_train.columns.values,\n",
    "        y= base_predictions_train.columns.values,\n",
    "          colorscale='Portland',\n",
    "            showscale=True,\n",
    "            reversescale = True\n",
    "    )\n",
    "]\n",
    "py.iplot(data, filename='labelled-heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_step2 = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train, xg_oof_train), axis=1)\n",
    "x_test_step2 = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test, xg_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = XGBClassifier(\n",
    "    #learning_rate = 0.02,\n",
    " n_estimators= 2000,\n",
    " max_depth= 4,\n",
    " min_child_weight= 2,\n",
    " #gamma=1,\n",
    " gamma=0.9,                        \n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " n_jobs= -1,\n",
    " scale_pos_weight=1).fit(x_train_step2, y_train)\n",
    "predictions = gbm.predict(x_test_step2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[504,  45],\n",
       "       [ 94, 248]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the Test set results\n",
    "y_pred_train = gbm.predict(x_train_step2)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train,y_pred_train)\n",
    "cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = pd.DataFrame({ 'PassengerId': PassengerId,\n",
    "                            'Survived': predictions })\n",
    "output.to_csv(\"StackingSubmission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
